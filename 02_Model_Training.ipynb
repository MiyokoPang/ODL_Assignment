{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc953af9",
   "metadata": {},
   "source": [
    "# Assignment 2: Model Building, Tuning, and Evaluation\n",
    "\n",
    "This notebook covers the end-to-end modeling process for the Customer Churn prediction task.\n",
    "\n",
    "### Objectives\n",
    "1.  **Task 1 (Model Building):** Build and compare two baseline Deep Learning models:\n",
    "    * **Model A:** A Deep Multi-Layer Perceptron (MLP).\n",
    "    * **Model B:** A 1-D Double-Layered Convolutional Neural Network (CNN), treating tabular features as spatial data.\n",
    "2.  **Task 2 (Model Tuning):** Use `Keras Tuner` to optimize the hyperparameters (filters, kernel size, dropout) of the CNN model.\n",
    "3.  **Task 3 (Model Evaluation):** Train the optimal model and evaluate it against the unseen test set using metrics like AUC-ROC, Precision, Recall, and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1. Setup and Library Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Keras Tuner for Hyperparameter Optimization\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. Data Loading and Preparation\n",
    "\n",
    "# Load datasets generated in Assignment 1\n",
    "base_dir = Path.cwd()\n",
    "train_df = pd.read_csv(base_dir / 'train_final.csv')\n",
    "test_df = pd.read_csv(base_dir / 'test_final.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop('Exited', axis=1)\n",
    "y_train = train_df['Exited']\n",
    "X_test = test_df.drop('Exited', axis=1)\n",
    "y_test = test_df['Exited']\n",
    "\n",
    "# --- DATA RESHAPING FOR CNN ---\n",
    "# 1D CNNs require input shape (Batch_Size, Steps, Channels).\n",
    "# We treat our tabular features as a sequence of length 'N_features' with 1 channel.\n",
    "X_train_cnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "print(f\"Original Feature Shape: {X_train.shape}\")\n",
    "print(f\"Reshaped CNN Input:     {X_train_cnn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ecb316",
   "metadata": {},
   "source": [
    "## Task 1: Model Building\n",
    "\n",
    "We will train two baseline models to compare their initial performance.\n",
    "1.  **Deeper MLP:** A dense network with multiple hidden layers and dropout.\n",
    "2.  **1-D CNN:** A convolutional network that looks for local patterns among features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-baseline-mlp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model A: Deeper MLP ---\n",
    "\n",
    "mlp_model = Sequential([\n",
    "    InputLayer(shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create validation split from training data for monitoring\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "print(\"Training Deeper MLP...\")\n",
    "history_mlp = mlp_model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_split=0.2, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    callbacks=[early_stop],\n",
    "    verbose=0 # Set to 1 to see per-epoch logs\n",
    ")\n",
    "print(\"MLP Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-baseline-cnn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model B: 1-D Double Layered CNN ---\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    # Input Layer (reshaped for CNN)\n",
    "    InputLayer(shape=(X_train.shape[1], 1)),\n",
    "    \n",
    "    # 1st Convolutional Block\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    \n",
    "    # 2nd Convolutional Block\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    \n",
    "    # Flatten and Dense Layers\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Training 1D CNN...\")\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_train_cnn, y_train, \n",
    "    validation_split=0.2, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "print(\"CNN Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-compare-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Model Performance\n",
    "def plot_comparison(h1, h2, name1=\"MLP\", name2=\"CNN\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    ax[0].plot(h1.history['val_accuracy'], label=f'{name1} Val Acc')\n",
    "    ax[0].plot(h2.history['val_accuracy'], label=f'{name2} Val Acc')\n",
    "    ax[0].set_title('Validation Accuracy Comparison')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    # Loss Plot\n",
    "    ax[1].plot(h1.history['val_loss'], label=f'{name1} Val Loss')\n",
    "    ax[1].plot(h2.history['val_loss'], label=f'{name2} Val Loss')\n",
    "    ax[1].set_title('Validation Loss Comparison')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_comparison(history_mlp, history_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10af37",
   "metadata": {},
   "source": [
    "## Task 2: Model Tuning with Keras Tuner\n",
    "\n",
    "We will perform hyperparameter tuning on the **1-D CNN architecture** to maximize validation accuracy. We will search for:\n",
    "1.  Optimal number of filters in convolution layers.\n",
    "2.  Optimal kernel size.\n",
    "3.  Optimal Dense layer units.\n",
    "4.  Learning Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-tuner-def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_hypermodel(hp):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(shape=(X_train.shape[1], 1)))\n",
    "    \n",
    "    # Tune 1st Conv Layer\n",
    "    hp_filters1 = hp.Int('filters_1', min_value=16, max_value=64, step=16)\n",
    "    hp_kernel = hp.Choice('kernel_size', values=[2, 3])\n",
    "    model.add(Conv1D(filters=hp_filters1, kernel_size=hp_kernel, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Tune 2nd Conv Layer\n",
    "    hp_filters2 = hp.Int('filters_2', min_value=32, max_value=128, step=32)\n",
    "    model.add(Conv1D(filters=hp_filters2, kernel_size=hp_kernel, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Tune Dense Layer\n",
    "    hp_dense = hp.Int('dense_units', min_value=32, max_value=128, step=32)\n",
    "    model.add(Dense(units=hp_dense, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Tune Learning Rate\n",
    "    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=hp_lr), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_cnn_hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Total combinations to try\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='churn_cnn_tuning',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Run Search\n",
    "print(\"Starting Hyperparameter Search...\")\n",
    "tuner.search(X_train_cnn, y_train, epochs=20, validation_split=0.2, callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-best-hps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Best Hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"--- Optimal Hyperparameters ---\")\n",
    "print(f\"Filters Layer 1: {best_hps.get('filters_1')}\")\n",
    "print(f\"Filters Layer 2: {best_hps.get('filters_2')}\")\n",
    "print(f\"Kernel Size:     {best_hps.get('kernel_size')}\")\n",
    "print(f\"Dense Units:     {best_hps.get('dense_units')}\")\n",
    "print(f\"Learning Rate:   {best_hps.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103be73",
   "metadata": {},
   "source": [
    "## Task 3: Final Model Evaluation\n",
    "\n",
    "We rebuild the best model and evaluate it on the **unseen test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-final-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model\n",
    "final_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train on full training data\n",
    "history_final = final_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Test Data\n",
    "print(\"\\n--- Evaluation on Test Set ---\")\n",
    "loss, accuracy = final_model.evaluate(X_test_cnn, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "y_pred_prob = final_model.predict(X_test_cnn)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Final CNN)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
